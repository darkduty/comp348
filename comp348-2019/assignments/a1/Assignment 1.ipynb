{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Python for Text Processing\n",
    "\n",
    "*Submission deadline: Friday 15 March 2019, 11:00pm*\n",
    "\n",
    "## Objectives of this assignment\n",
    "\n",
    "In this assignment you will practice with the use of Python for text processing. You will be asked to implement tf.idf and cosine similarity from scratch. Normally you would use packaged libraries that implement these, and the lecture notes show how to use some of them. But in this assignment you are asked to implement them without using these libraries. This way you will achieve a better understanding of the mechanics of tf.idf and cosine similarity, and you get to practice with programming in Python.\n",
    "\n",
    "The deadline of this assignment is before census date, so it can serve as a diagnostic test and you can determine if you want to remain in the unit or withdraw without penalty.\n",
    "\n",
    "Below are the questions of this assignment. They are in the format of a Jupyter notebook so that you can use this notebook to work on your solution. Write the final solution in a standalone Python file as described in the \"submission\" section by the end of these assignment specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top tokens (1 mark)\n",
    "\n",
    "Implement a function that returns a list of the $n$ most frequent non-stop tokens, sorted by frequency. Make sure that the list of tokens returned is lowercased, and that all comparisons with the list of stop words are not case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute term frequencies (1 mark)\n",
    "\n",
    "Implement a function that returns the frequency of each of the tokens provided as a parameter to the function. Make sure that the comparisons made are not case sensitive. To compute the frequencies you may use the `Counter` class of the `collections` module if you think it may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the inverse document frequency (1 mark)\n",
    "\n",
    "Implement a function that returns a list of inverse document frequencies of the tokens provided as a parameter to the function. Again, make sure that the comparisons are not case sensitive. The inverse document frequency is computed by the formula indicated in the lectures:\n",
    "\n",
    "$$\n",
    "\\hbox{idf}(t) = \\log_{10}\\frac{\\hbox{number of documents}}{\\hbox{number of documents that contain}\\ t}\n",
    "$$\n",
    "\n",
    "You may use the `Counter` class of the `collections` module if you think it may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute tf.idf (1 mark)\n",
    "\n",
    "Implement a function that returns the tf.idf of each document listed in the function arguments. Make sure that the idf is computed relative to the text collection provided. The list should return the tf.idf values of the words provided in the template. Again, make sure that all comparisons are not case sensitive. To implement this function you may use calls to the functions implemented in the other exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the cosine similarity (1 mark)\n",
    "\n",
    "Implement a function that returns the cosine similarity between the tf.idf of two texts. The cosine similarity is defined with the formula given in the lectures:\n",
    "\n",
    "$$\n",
    "\\cos(X,Y) = \\frac{\\sum_i(X_i\\times Y_i)}{\\sqrt{\\sum_iX^2_i}\\times \\sqrt{\\sum_iY^2_i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Submit a single Python file with the solutions to all the questions. We provide a template defines all the functions as stubs. Make sure that you do not change the names and argument structure of the functions, since the submission will use an automatic marker that relies on these exact names and argument structure. The template we provide includes a few simple tests using [Python's doctest](https://docs.python.org/3/library/doctest.html) environment. These tests are there to help you, but note that we may use a separate set of tests when we assess your submission. It is your responsibility to run your own tests, in addition to the doctests provided.\n",
    "\n",
    "The submission must be a single Python file. Do not submit several files or a zip file since the automarker would not know what to do with your submission.\n",
    "\n",
    "Note that the deadline is a hard deadline and there will be a penalty of one mark per day of late submission. In addition, since the submission date is less than a week before the census date of 21 of March 2018, late submissions might not be assessed before census date.\n",
    "\n",
    "Finally, note that **the work submitted should be your own work**. You may be tempted to search the Web for Python implementations of the questions asked in this tutorial. Be aware that:\n",
    "\n",
    "1. If we find out that your work is copied from the Web or from other submissions, you may face disciplinary action.\n",
    "2. Often, trying to adapt work from the web may be more difficult than when you try from scratch.\n",
    "3. The work you find on the web may be wrong or not do exactly what is asked in this assignment anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
